<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ise.pipelines.training API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ise.pipelines.training</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from ise.models.training.Trainer import Trainer
from ise.models.traditional import ExploratoryModel
from ise.models.timeseries import TimeSeriesEmulator
from ise.models.traditional.ExploratoryModel import ExploratoryModel
from ise.models.gp.GaussianProcess import GP
from torch import nn
import pandas as pd
import os
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF
import numpy as np
np.random.seed(10)
from sklearn.metrics import r2_score
from sklearn.decomposition import PCA



def train_timeseries_network(data_directory, 
                             architecture=None, 
                             epochs=20, 
                             batch_size=100, 
                             model=TimeSeriesEmulator,
                             loss=nn.MSELoss(),
                             mc_dropout=True,
                             dropout_prob=0.1,
                             tensorboard=False,
                             save_model=False,
                             performance_optimized=False,
                             verbose=False,
                             tensorboard_comment=None
                             ):
    
    if verbose:
        print(&#39;1/3: Loading processed data...&#39;)
    try:
        test_features = pd.read_csv(f&#39;{data_directory}/ts_test_features.csv&#39;)
        train_features = pd.read_csv(f&#39;{data_directory}/ts_train_features.csv&#39;)
        test_labels = pd.read_csv(f&#39;{data_directory}/ts_test_labels.csv&#39;)
        train_labels = pd.read_csv(f&#39;{data_directory}/ts_train_labels.csv&#39;)
        scenarios = pd.read_csv(f&#39;{data_directory}/ts_test_scenarios.csv&#39;).values.tolist()
    except FileNotFoundError:
            raise FileNotFoundError(&#39;Files not found. Format must be in format \&#34;ts_train_features.csv\&#34;&#39;)
        
    data_dict = {&#39;train_features&#39;: train_features,
                &#39;train_labels&#39;: train_labels,
                &#39;test_features&#39;: test_features,
                &#39;test_labels&#39;: test_labels, }
    
    trainer = Trainer()
    if verbose:
        print(&#39;2/3: Training Model...&#39;)
        
    if architecture is None:
        architecture = {
            &#39;num_rnn_layers&#39;: 4,
            &#39;num_rnn_hidden&#39;: 128,
        }
    
    print(&#39;Architecture: &#39;)
    print(architecture)

    trainer.train(
        model=model,
        architecture=architecture,
        data_dict=data_dict,
        criterion=loss,
        epochs=epochs,
        batch_size=batch_size,
        mc_dropout=mc_dropout,
        dropout_prob=dropout_prob,
        tensorboard=tensorboard,
        save_model=save_model,
        performance_optimized=performance_optimized,
        sequence_length=5,
        verbose=verbose,
        tensorboard_comment=tensorboard_comment,
    )

    if verbose:
        print(&#39;3/3: Evaluating Model&#39;)
    model = trainer.model
    metrics, test_preds = trainer.evaluate(verbose=verbose)
    return model, metrics, test_preds


def train_traditional_network(data_directory, 
                             architecture=None, 
                             epochs=20, 
                             batch_size=100, 
                             model=ExploratoryModel,
                             loss=nn.MSELoss(),
                             tensorboard=False,
                             save_model=False,
                             performance_optimized=False,
                             verbose=False,
                             tensorboard_comment=None
                             ):
    
    if verbose:
        print(&#39;1/3: Loading processed data&#39;)
    
    try:
        test_features = pd.read_csv(f&#39;{data_directory}/traditional_test_features.csv&#39;)
        train_features = pd.read_csv(f&#39;{data_directory}/traditional_train_features.csv&#39;)
        test_labels = pd.read_csv(f&#39;{data_directory}/traditional_test_labels.csv&#39;)
        train_labels = pd.read_csv(f&#39;{data_directory}/traditional_train_labels.csv&#39;)
        scenarios = pd.read_csv(f&#39;{data_directory}/traditional_test_scenarios.csv&#39;).values.tolist()
    except FileNotFoundError:
            raise FileNotFoundError(&#39;Files not found. Format must be in format \&#34;traditional_train_features.csv\&#34;&#39;)
    
    if &#39;lag&#39; in train_features.columns:
        raise AttributeError(&#39;Data must be processed using timeseries=True in feataure_engineering. Rerun feature engineering to train traditional network.&#39;)
        
    data_dict = {&#39;train_features&#39;: train_features,
                &#39;train_labels&#39;: train_labels,
                &#39;test_features&#39;: test_features,
                &#39;test_labels&#39;: test_labels, }
    
    trainer = Trainer()
    if verbose:
        print(&#39;2/3: Training Model&#39;)
        
    if architecture is None:
        architecture = {
            &#39;num_linear_layers&#39;: 4,
            &#39;nodes&#39;: [128, 64, 32, 1],
        }

    trainer.train(
        model=model,
        architecture=architecture,
        data_dict=data_dict,
        criterion=loss,
        epochs=epochs,
        batch_size=batch_size,
        tensorboard=tensorboard,
        save_model=save_model,
        performance_optimized=performance_optimized,
        sequence_length=5,
        verbose=verbose,
        tensorboard_comment=tensorboard_comment,
    )

    if verbose:
        print(&#39;3/3: Evaluating Model&#39;)
    model = trainer.model
    metrics, test_preds = trainer.evaluate(verbose=verbose)
    return metrics, test_preds

def train_gaussian_process(data_directory, n, features=[&#39;temperature&#39;], sampling_method=&#39;random&#39;, kernel=None, verbose=False, save_directory=None):
    
    if verbose:
        print(&#39;1/3: Loading processed data...&#39;)
    
    try:
        test_features = pd.read_csv(f&#39;{data_directory}/traditional_test_features.csv&#39;)
        train_features = pd.read_csv(f&#39;{data_directory}/traditional_train_features.csv&#39;)
        test_labels = pd.read_csv(f&#39;{data_directory}/traditional_test_labels.csv&#39;)
        train_labels = pd.read_csv(f&#39;{data_directory}/traditional_train_labels.csv&#39;)
        scenarios = pd.read_csv(f&#39;{data_directory}/traditional_test_scenarios.csv&#39;).values.tolist()
    except FileNotFoundError:
        test_features = pd.read_csv(f&#39;{data_directory}/ts_test_features.csv&#39;)
        train_features = pd.read_csv(f&#39;{data_directory}/ts_train_features.csv&#39;)
        test_labels = pd.read_csv(f&#39;{data_directory}/ts_test_labels.csv&#39;)
        train_labels = pd.read_csv(f&#39;{data_directory}/ts_train_labels.csv&#39;)
        scenarios = pd.read_csv(f&#39;{data_directory}/ts_test_scenarios.csv&#39;).values.tolist()
    
    if not isinstance(features, list):
        raise ValueError(f&#39;features argument must be a list, received {type(features)}&#39;)
    
    # type check features
    if not isinstance(features, list):
        raise AttributeError(f&#39;features argument must be of type list, received {type(features)}&#39;)
    
    # See if features argument contain columns or principal components
    features_are_pcs = all([f.lower().startswith(&#39;pc&#39;) for f in features])
    features_are_columns = all([f in train_features.columns for f in features])
    
    if features_are_columns:
        # subset dataframe based on columns
        gp_train_features = train_features[features]
        gp_test_features = test_features[features]
    
    elif features_are_pcs:
        # run PCA with the len(features) be the number of PCs
        train_features[&#39;set&#39;] = &#39;train&#39;
        test_features[&#39;set&#39;] = &#39;test&#39;
        pca_features = pd.concat([train_features, test_features])
        pca = PCA(n_components=len(features))
        principalComponents = pca.fit_transform(pca_features.drop(columns=[&#39;set&#39;]))
        gp_train_features = pd.DataFrame(principalComponents[pca_features[&#39;set&#39;] == &#39;train&#39;].squeeze())
        gp_test_features = pd.DataFrame(principalComponents[pca_features[&#39;set&#39;] == &#39;test&#39;].squeeze())
    
    else:
        raise ValueError(&#39;Features must all be in train_features.columns or must all be PCs, e.g. [pc1, pc2, pc3]&#39;)
    
    # Handle subsetting data -- randomly drawn or first N
    if sampling_method.lower() == &#39;random&#39;:
        gp_train_features = gp_train_features.sample(n)
    elif sampling_method.lower() == &#39;first_n&#39;:
        gp_train_features = gp_train_features[:n]
    else:
        raise ValueError(f&#39;sampling method must be in [random, first_n], received {sampling_method}&#39;)
    
    
    # Format datasets
    gp_train_labels = np.array(train_labels.loc[gp_train_features.index])
    if isinstance(gp_train_features, pd.Series) or gp_train_features.shape[1] == 1:
        gp_train_features = np.array(gp_train_features).reshape(-1, 1)
    if isinstance(gp_test_features, pd.Series) or gp_test_features.ndim == 1:
        gp_test_features = np.array(gp_test_features).reshape(-1, 1)
     
    # Initiate model classes
    if kernel is None:
        kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-6, 1e2))
    gaussian_process = GP(kernel=kernel)
    
    if verbose:
        print(&#39;2/3: Training Model...&#39;)
        
    # fit data (same as gaussian_process.fit())
    gaussian_process.train(gp_train_features, gp_train_labels,)
    
    if verbose:
        print(&#39;3/3: Evaluating Model&#39;)
        
    # evaluate on test
    preds, std_prediction, metrics = gaussian_process.test(gp_test_features, test_labels)
        
    if save_directory:
        if isinstance(save_directory, str):
            preds_path = f&#34;{save_directory}/preds.csv&#34;
            uq_path = f&#34;{save_directory}/std.csv&#34;
            
        elif isinstance(save_directory, bool):
            preds_path = f&#34;preds.csv&#34;
            uq_path = f&#34;std.csv&#34;
        
        pd.Series(preds, name=&#39;preds&#39;).to_csv(preds_path, index=False)
        pd.Series(std_prediction, name=&#39;std_prediction&#39;).to_csv(uq_path, index=False)

    
    return preds, std_prediction, metrics</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ise.pipelines.training.train_gaussian_process"><code class="name flex">
<span>def <span class="ident">train_gaussian_process</span></span>(<span>data_directory, n, features=['temperature'], sampling_method='random', kernel=None, verbose=False, save_directory=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_gaussian_process(data_directory, n, features=[&#39;temperature&#39;], sampling_method=&#39;random&#39;, kernel=None, verbose=False, save_directory=None):
    
    if verbose:
        print(&#39;1/3: Loading processed data...&#39;)
    
    try:
        test_features = pd.read_csv(f&#39;{data_directory}/traditional_test_features.csv&#39;)
        train_features = pd.read_csv(f&#39;{data_directory}/traditional_train_features.csv&#39;)
        test_labels = pd.read_csv(f&#39;{data_directory}/traditional_test_labels.csv&#39;)
        train_labels = pd.read_csv(f&#39;{data_directory}/traditional_train_labels.csv&#39;)
        scenarios = pd.read_csv(f&#39;{data_directory}/traditional_test_scenarios.csv&#39;).values.tolist()
    except FileNotFoundError:
        test_features = pd.read_csv(f&#39;{data_directory}/ts_test_features.csv&#39;)
        train_features = pd.read_csv(f&#39;{data_directory}/ts_train_features.csv&#39;)
        test_labels = pd.read_csv(f&#39;{data_directory}/ts_test_labels.csv&#39;)
        train_labels = pd.read_csv(f&#39;{data_directory}/ts_train_labels.csv&#39;)
        scenarios = pd.read_csv(f&#39;{data_directory}/ts_test_scenarios.csv&#39;).values.tolist()
    
    if not isinstance(features, list):
        raise ValueError(f&#39;features argument must be a list, received {type(features)}&#39;)
    
    # type check features
    if not isinstance(features, list):
        raise AttributeError(f&#39;features argument must be of type list, received {type(features)}&#39;)
    
    # See if features argument contain columns or principal components
    features_are_pcs = all([f.lower().startswith(&#39;pc&#39;) for f in features])
    features_are_columns = all([f in train_features.columns for f in features])
    
    if features_are_columns:
        # subset dataframe based on columns
        gp_train_features = train_features[features]
        gp_test_features = test_features[features]
    
    elif features_are_pcs:
        # run PCA with the len(features) be the number of PCs
        train_features[&#39;set&#39;] = &#39;train&#39;
        test_features[&#39;set&#39;] = &#39;test&#39;
        pca_features = pd.concat([train_features, test_features])
        pca = PCA(n_components=len(features))
        principalComponents = pca.fit_transform(pca_features.drop(columns=[&#39;set&#39;]))
        gp_train_features = pd.DataFrame(principalComponents[pca_features[&#39;set&#39;] == &#39;train&#39;].squeeze())
        gp_test_features = pd.DataFrame(principalComponents[pca_features[&#39;set&#39;] == &#39;test&#39;].squeeze())
    
    else:
        raise ValueError(&#39;Features must all be in train_features.columns or must all be PCs, e.g. [pc1, pc2, pc3]&#39;)
    
    # Handle subsetting data -- randomly drawn or first N
    if sampling_method.lower() == &#39;random&#39;:
        gp_train_features = gp_train_features.sample(n)
    elif sampling_method.lower() == &#39;first_n&#39;:
        gp_train_features = gp_train_features[:n]
    else:
        raise ValueError(f&#39;sampling method must be in [random, first_n], received {sampling_method}&#39;)
    
    
    # Format datasets
    gp_train_labels = np.array(train_labels.loc[gp_train_features.index])
    if isinstance(gp_train_features, pd.Series) or gp_train_features.shape[1] == 1:
        gp_train_features = np.array(gp_train_features).reshape(-1, 1)
    if isinstance(gp_test_features, pd.Series) or gp_test_features.ndim == 1:
        gp_test_features = np.array(gp_test_features).reshape(-1, 1)
     
    # Initiate model classes
    if kernel is None:
        kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-6, 1e2))
    gaussian_process = GP(kernel=kernel)
    
    if verbose:
        print(&#39;2/3: Training Model...&#39;)
        
    # fit data (same as gaussian_process.fit())
    gaussian_process.train(gp_train_features, gp_train_labels,)
    
    if verbose:
        print(&#39;3/3: Evaluating Model&#39;)
        
    # evaluate on test
    preds, std_prediction, metrics = gaussian_process.test(gp_test_features, test_labels)
        
    if save_directory:
        if isinstance(save_directory, str):
            preds_path = f&#34;{save_directory}/preds.csv&#34;
            uq_path = f&#34;{save_directory}/std.csv&#34;
            
        elif isinstance(save_directory, bool):
            preds_path = f&#34;preds.csv&#34;
            uq_path = f&#34;std.csv&#34;
        
        pd.Series(preds, name=&#39;preds&#39;).to_csv(preds_path, index=False)
        pd.Series(std_prediction, name=&#39;std_prediction&#39;).to_csv(uq_path, index=False)

    
    return preds, std_prediction, metrics</code></pre>
</details>
</dd>
<dt id="ise.pipelines.training.train_timeseries_network"><code class="name flex">
<span>def <span class="ident">train_timeseries_network</span></span>(<span>data_directory, architecture=None, epochs=20, batch_size=100, model=ise.models.timeseries.TimeSeriesEmulator.TimeSeriesEmulator, loss=MSELoss(), mc_dropout=True, dropout_prob=0.1, tensorboard=False, save_model=False, performance_optimized=False, verbose=False, tensorboard_comment=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_timeseries_network(data_directory, 
                             architecture=None, 
                             epochs=20, 
                             batch_size=100, 
                             model=TimeSeriesEmulator,
                             loss=nn.MSELoss(),
                             mc_dropout=True,
                             dropout_prob=0.1,
                             tensorboard=False,
                             save_model=False,
                             performance_optimized=False,
                             verbose=False,
                             tensorboard_comment=None
                             ):
    
    if verbose:
        print(&#39;1/3: Loading processed data...&#39;)
    try:
        test_features = pd.read_csv(f&#39;{data_directory}/ts_test_features.csv&#39;)
        train_features = pd.read_csv(f&#39;{data_directory}/ts_train_features.csv&#39;)
        test_labels = pd.read_csv(f&#39;{data_directory}/ts_test_labels.csv&#39;)
        train_labels = pd.read_csv(f&#39;{data_directory}/ts_train_labels.csv&#39;)
        scenarios = pd.read_csv(f&#39;{data_directory}/ts_test_scenarios.csv&#39;).values.tolist()
    except FileNotFoundError:
            raise FileNotFoundError(&#39;Files not found. Format must be in format \&#34;ts_train_features.csv\&#34;&#39;)
        
    data_dict = {&#39;train_features&#39;: train_features,
                &#39;train_labels&#39;: train_labels,
                &#39;test_features&#39;: test_features,
                &#39;test_labels&#39;: test_labels, }
    
    trainer = Trainer()
    if verbose:
        print(&#39;2/3: Training Model...&#39;)
        
    if architecture is None:
        architecture = {
            &#39;num_rnn_layers&#39;: 4,
            &#39;num_rnn_hidden&#39;: 128,
        }
    
    print(&#39;Architecture: &#39;)
    print(architecture)

    trainer.train(
        model=model,
        architecture=architecture,
        data_dict=data_dict,
        criterion=loss,
        epochs=epochs,
        batch_size=batch_size,
        mc_dropout=mc_dropout,
        dropout_prob=dropout_prob,
        tensorboard=tensorboard,
        save_model=save_model,
        performance_optimized=performance_optimized,
        sequence_length=5,
        verbose=verbose,
        tensorboard_comment=tensorboard_comment,
    )

    if verbose:
        print(&#39;3/3: Evaluating Model&#39;)
    model = trainer.model
    metrics, test_preds = trainer.evaluate(verbose=verbose)
    return model, metrics, test_preds</code></pre>
</details>
</dd>
<dt id="ise.pipelines.training.train_traditional_network"><code class="name flex">
<span>def <span class="ident">train_traditional_network</span></span>(<span>data_directory, architecture=None, epochs=20, batch_size=100, model=ise.models.traditional.ExploratoryModel.ExploratoryModel, loss=MSELoss(), tensorboard=False, save_model=False, performance_optimized=False, verbose=False, tensorboard_comment=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_traditional_network(data_directory, 
                             architecture=None, 
                             epochs=20, 
                             batch_size=100, 
                             model=ExploratoryModel,
                             loss=nn.MSELoss(),
                             tensorboard=False,
                             save_model=False,
                             performance_optimized=False,
                             verbose=False,
                             tensorboard_comment=None
                             ):
    
    if verbose:
        print(&#39;1/3: Loading processed data&#39;)
    
    try:
        test_features = pd.read_csv(f&#39;{data_directory}/traditional_test_features.csv&#39;)
        train_features = pd.read_csv(f&#39;{data_directory}/traditional_train_features.csv&#39;)
        test_labels = pd.read_csv(f&#39;{data_directory}/traditional_test_labels.csv&#39;)
        train_labels = pd.read_csv(f&#39;{data_directory}/traditional_train_labels.csv&#39;)
        scenarios = pd.read_csv(f&#39;{data_directory}/traditional_test_scenarios.csv&#39;).values.tolist()
    except FileNotFoundError:
            raise FileNotFoundError(&#39;Files not found. Format must be in format \&#34;traditional_train_features.csv\&#34;&#39;)
    
    if &#39;lag&#39; in train_features.columns:
        raise AttributeError(&#39;Data must be processed using timeseries=True in feataure_engineering. Rerun feature engineering to train traditional network.&#39;)
        
    data_dict = {&#39;train_features&#39;: train_features,
                &#39;train_labels&#39;: train_labels,
                &#39;test_features&#39;: test_features,
                &#39;test_labels&#39;: test_labels, }
    
    trainer = Trainer()
    if verbose:
        print(&#39;2/3: Training Model&#39;)
        
    if architecture is None:
        architecture = {
            &#39;num_linear_layers&#39;: 4,
            &#39;nodes&#39;: [128, 64, 32, 1],
        }

    trainer.train(
        model=model,
        architecture=architecture,
        data_dict=data_dict,
        criterion=loss,
        epochs=epochs,
        batch_size=batch_size,
        tensorboard=tensorboard,
        save_model=save_model,
        performance_optimized=performance_optimized,
        sequence_length=5,
        verbose=verbose,
        tensorboard_comment=tensorboard_comment,
    )

    if verbose:
        print(&#39;3/3: Evaluating Model&#39;)
    model = trainer.model
    metrics, test_preds = trainer.evaluate(verbose=verbose)
    return metrics, test_preds</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ise.pipelines" href="index.html">ise.pipelines</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ise.pipelines.training.train_gaussian_process" href="#ise.pipelines.training.train_gaussian_process">train_gaussian_process</a></code></li>
<li><code><a title="ise.pipelines.training.train_timeseries_network" href="#ise.pipelines.training.train_timeseries_network">train_timeseries_network</a></code></li>
<li><code><a title="ise.pipelines.training.train_traditional_network" href="#ise.pipelines.training.train_traditional_network">train_traditional_network</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>
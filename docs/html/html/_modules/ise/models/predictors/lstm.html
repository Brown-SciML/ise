

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ise.models.predictors.lstm &mdash; ise 1.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />

  
    <link rel="canonical" href="/_modules/ise/models/predictors/lstm.html" />
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=fc837d61"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            ise
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../docs/source/ise.html">ise documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">ise</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">ise.models.predictors.lstm</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for ise.models.predictors.lstm</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">ise.utils.functions</span> <span class="kn">import</span> <span class="n">to_tensor</span>
<span class="kn">from</span> <span class="nn">ise.data.dataclasses</span> <span class="kn">import</span> <span class="n">EmulatorDataset</span>
<span class="kn">from</span> <span class="nn">ise.utils.training</span> <span class="kn">import</span> <span class="n">CheckpointSaver</span><span class="p">,</span> <span class="n">EarlyStoppingCheckpointer</span>

<div class="viewcode-block" id="LSTM">
<a class="viewcode-back" href="../../../../docs/source/ise.models.predictors.html#ise.models.predictors.lstm.LSTM">[docs]</a>
<span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Long Short-Term Memory (LSTM) model for time series forecasting.</span>

<span class="sd">    This class implements an LSTM network with multiple layers, dropout, and fully connected</span>
<span class="sd">    layers to generate predictions for sequential data.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        lstm_num_layers (int): Number of LSTM layers in the model.</span>
<span class="sd">        lstm_num_hidden (int): Number of hidden units in each LSTM layer.</span>
<span class="sd">        input_size (int): Number of input features.</span>
<span class="sd">        output_size (int): Number of output features.</span>
<span class="sd">        output_sequence_length (int): Number of time steps predicted by the model.</span>
<span class="sd">        device (str): Device on which the model runs (&#39;cuda&#39; or &#39;cpu&#39;).</span>
<span class="sd">        lstm (nn.LSTM): LSTM layer for sequence modeling.</span>
<span class="sd">        relu (nn.ReLU): ReLU activation function.</span>
<span class="sd">        linear1 (nn.Linear): Intermediate fully connected layer.</span>
<span class="sd">        linear_out (nn.Linear): Output layer mapping to final predictions.</span>
<span class="sd">        optimizer (torch.optim.Optimizer): Optimization algorithm used for training.</span>
<span class="sd">        dropout (nn.Dropout): Dropout layer to prevent overfitting.</span>
<span class="sd">        criterion (torch.nn.modules.loss._Loss): Loss function used for training.</span>
<span class="sd">        trained (bool): Flag indicating whether the model has been trained.</span>

<span class="sd">    Args:</span>
<span class="sd">        lstm_num_layers (int): Number of LSTM layers.</span>
<span class="sd">        lstm_hidden_size (int): Number of hidden units in each LSTM layer.</span>
<span class="sd">        input_size (int, optional): Number of input features. Defaults to 83.</span>
<span class="sd">        output_size (int, optional): Number of output features. Defaults to 1.</span>
<span class="sd">        criterion (torch.nn.modules.loss._Loss, optional): Loss function. Defaults to MSELoss.</span>
<span class="sd">        output_sequence_length (int, optional): Number of output time steps. Defaults to 86.</span>
<span class="sd">        optimizer (torch.optim.Optimizer, optional): Optimizer type. Defaults to Adam.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lstm_num_layers</span><span class="p">,</span>
        <span class="n">lstm_hidden_size</span><span class="p">,</span>
        <span class="n">input_size</span><span class="o">=</span><span class="mi">83</span><span class="p">,</span>
        <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">criterion</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span>
        <span class="n">output_sequence_length</span><span class="o">=</span><span class="mi">86</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Initialize attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_num_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lstm_num_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_num_hidden</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lstm_hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_sequence_length</span> <span class="o">=</span> <span class="n">output_sequence_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Initialize model layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">input_size</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">lstm_hidden_size</span><span class="p">),</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">lstm_num_layers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">lstm_hidden_size</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">output_size</span><span class="p">)</span>

        <span class="c1"># Initialize optimizer and other components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="LSTM.forward">
<a class="viewcode-back" href="../../../../docs/source/ise.models.predictors.html#ise.models.predictors.lstm.LSTM.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs a forward pass through the LSTM network.</span>

<span class="sd">        Given an input sequence, the LSTM processes the sequence to extract features,</span>
<span class="sd">        which are passed through a fully connected network to generate predictions.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (Tensor): Input tensor of shape (batch_size, sequence_length, input_size).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Output tensor of shape (batch_size, output_size), representing </span>
<span class="sd">            the modelâ€™s predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">h0</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm_num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_num_hidden</span><span class="p">)</span>
            <span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
            <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">c0</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm_num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_num_hidden</span><span class="p">)</span>
            <span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
            <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">hn</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>

        <span class="c1"># Perform linear layer operations</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span></div>

    
    
<div class="viewcode-block" id="LSTM.fit">
<a class="viewcode-back" href="../../../../docs/source/ise.models.predictors.html#ise.models.predictors.lstm.LSTM.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">X_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
            <span class="n">save_checkpoints</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="o">=</span><span class="s1">&#39;checkpoint.pt&#39;</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dataclass</span><span class="o">=</span><span class="n">EmulatorDataset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the LSTM model on the provided data.</span>

<span class="sd">        Supports optional checkpointing and early stopping. If a checkpoint exists, </span>
<span class="sd">        training resumes from the last saved state.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (Tensor or DataFrame): Input training data.</span>
<span class="sd">            y (Tensor or DataFrame): Target values corresponding to the input data.</span>
<span class="sd">            epochs (int, optional): Number of epochs for training. Defaults to 100.</span>
<span class="sd">            sequence_length (int, optional): Length of input sequences. Defaults to 5.</span>
<span class="sd">            batch_size (int, optional): Batch size used in training. Defaults to 64.</span>
<span class="sd">            criterion (torch.nn.modules.loss._Loss, optional): Loss function. Defaults to None.</span>
<span class="sd">            X_val (Tensor or DataFrame, optional): Validation input data. Defaults to None.</span>
<span class="sd">            y_val (Tensor or DataFrame, optional): Validation target data. Defaults to None.</span>
<span class="sd">            save_checkpoints (bool, optional): Whether to save model checkpoints. Defaults to True.</span>
<span class="sd">            checkpoint_path (str, optional): Path to save model checkpoints. Defaults to &#39;checkpoint.pt&#39;.</span>
<span class="sd">            early_stopping (bool, optional): Whether to enable early stopping. Defaults to False.</span>
<span class="sd">            patience (int, optional): Number of epochs to wait before stopping. Defaults to 10.</span>
<span class="sd">            verbose (bool, optional): Whether to print training progress. Defaults to True.</span>
<span class="sd">            dataclass (type, optional): Dataset class for handling data. Defaults to EmulatorDataset.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If no loss function is provided.</span>

<span class="sd">        Notes:</span>
<span class="sd">            - If validation data is provided but early stopping is disabled, a warning is issued.</span>
<span class="sd">            - If a checkpoint exists, training resumes from the saved epoch.</span>
<span class="sd">            - If early stopping is enabled, the model stops training when validation loss stops improving.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            
        <span class="c1"># Check if a checkpoint exists and load it</span>
        <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">best_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">checkpoint_path</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">):</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
            <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">best_loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;best_loss&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Resuming from checkpoint at epoch </span><span class="si">{</span><span class="n">start_epoch</span><span class="si">}</span><span class="s2"> with validation loss </span><span class="si">{</span><span class="n">best_loss</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        
        <span class="c1"># Check if validation data is provided</span>
        <span class="k">if</span> <span class="n">X_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">validate</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">early_stopping</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;Validation data provided but early_stopping is False. Early stopping is recommended for validation data.&quot;</span>
                <span class="p">)</span>
            <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">y_val</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">validate</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Set loss criterion</span>
        <span class="k">if</span> <span class="n">criterion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">criterion</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;loss must be provided if criterion is None.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Convert data to numpy arrays if pandas DataFrames</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span>

        <span class="c1"># Create dataset and data loader</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataclass</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">projection_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_sequence_length</span><span class="p">)</span>
        <span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Set model to training mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Initialize early stopping</span>
        <span class="k">if</span> <span class="n">save_checkpoints</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">early_stopping</span><span class="p">:</span>
                <span class="n">checkpointer</span> <span class="o">=</span> <span class="n">EarlyStoppingCheckpointer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">patience</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">checkpointer</span> <span class="o">=</span> <span class="n">CheckpointSaver</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)</span>
                
            <span class="n">checkpointer</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">best_loss</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">checkpointer</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="c1"># Training loop</span>
        <span class="k">if</span> <span class="n">start_epoch</span> <span class="o">&lt;</span> <span class="n">epochs</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
                <span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># Renamed to &#39;loss&#39; for clarity</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">batch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                <span class="c1"># Print average batch loss and validation loss (if provided)</span>
                <span class="k">if</span> <span class="n">validate</span><span class="p">:</span>
                    <span class="n">val_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                        <span class="n">X_val</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">val_preds</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">y_val</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

                    <span class="k">if</span> <span class="n">save_checkpoints</span><span class="p">:</span>
                        <span class="n">checkpointer</span><span class="p">(</span><span class="n">val_loss</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">checkpointer</span><span class="p">,</span> <span class="s2">&quot;early_stop&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">checkpointer</span><span class="o">.</span><span class="n">early_stop</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Early stopping&quot;</span><span class="p">)</span> 
                            <span class="k">break</span>
                        
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[epoch/total]: [</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">], train loss: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span><span class="si">}</span><span class="s2">, val mse: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> -- </span><span class="si">{</span><span class="nb">getattr</span><span class="p">(</span><span class="n">checkpointer</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;log&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">checkpointer</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">average_batch_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_losses</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[epoch/total]: [</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">], train loss: </span><span class="si">{</span><span class="n">average_batch_loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training already completed (</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">True</span>
        
        <span class="c1"># loads best model</span>
        <span class="k">if</span> <span class="n">save_checkpoints</span><span class="p">:</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="s1">&#39;model_state_dict&#39;</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;best_loss&#39;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">epochs_trained</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span></div>

            <span class="c1"># os.remove(checkpoint_path)</span>

<div class="viewcode-block" id="LSTM.predict">
<a class="viewcode-back" href="../../../../docs/source/ise.models.predictors.html#ise.models.predictors.lstm.LSTM.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dataclass</span><span class="o">=</span><span class="n">EmulatorDataset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates predictions using the trained LSTM model.</span>

<span class="sd">        The model processes input sequences and returns predictions. Predictions are computed</span>
<span class="sd">        in a batch-wise manner to optimize memory usage.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (Tensor or DataFrame): Input data for prediction.</span>
<span class="sd">            sequence_length (int, optional): Length of input sequences. Defaults to 5.</span>
<span class="sd">            batch_size (int, optional): Batch size used for inference. Defaults to 64.</span>
<span class="sd">            dataclass (type, optional): Dataset class for handling data. Defaults to EmulatorDataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Predicted values for the input data.</span>

<span class="sd">        Notes:</span>
<span class="sd">            - The model is set to evaluation mode before making predictions.</span>
<span class="sd">            - Data is converted to tensors if initially provided as pandas DataFrames.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Convert data to numpy array if pandas DataFrame</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>

        <span class="c1"># Create dataset and data loader</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataclass</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">projection_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_sequence_length</span><span class="p">)</span>
        <span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">X_test_batch</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="n">X_test_batch</span> <span class="o">=</span> <span class="n">X_test_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X_test_batch</span><span class="p">)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">preds</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">preds</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Peter Van Katwyk.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
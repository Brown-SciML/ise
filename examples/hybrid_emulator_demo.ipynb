{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a3f852",
   "metadata": {},
   "source": [
    "# Ice Sheet Emulator Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebd4e4",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "To install, run this is your terminal. This will create an environment, download ISE, and activate a jupyter notebook instance. Open up this notebook to run the model.  \n",
    "\n",
    "```conda create -n ise -y```  \n",
    "```conda activate ise```  \n",
    "```conda install nb_conda ipykernel -y```  \n",
    "```pip install git+https://github.com/Brown-SciML/ise```  \n",
    "```jupyter notebook```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b67923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/Brown-SciML/ise --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13a05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ise.models.hybrid import HybridEmulator, DeepEnsemble, NormalizingFlow\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882b6e8",
   "metadata": {},
   "source": [
    "### Synthetic Data and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a814d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3], [4,5,6], [7,8,9]], dtype=int)\n",
    "y = np.array([[1], [2], [3],], dtype=int)\n",
    "\n",
    "scaler_y = StandardScaler().fit(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8847c8d1",
   "metadata": {},
   "source": [
    "### Create emulator Model\n",
    "Create the model with the Deep Ensemble as the Predictor and the Normalizing Flow as the uncertainty quantifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0beb86de",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "hidden_size should be of type int, got: int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m num_ensemble_members \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 5\u001b[0m predictor \u001b[38;5;241m=\u001b[39m DeepEnsemble(num_predictors\u001b[38;5;241m=\u001b[39mnum_ensemble_members, forcing_size\u001b[38;5;241m=\u001b[39minput_shape, sle_size\u001b[38;5;241m=\u001b[39moutput_shape)\n\u001b[1;32m      6\u001b[0m uncertainty_quantifier \u001b[38;5;241m=\u001b[39m NormalizingFlow(forcing_size\u001b[38;5;241m=\u001b[39minput_shape, sle_size\u001b[38;5;241m=\u001b[39moutput_shape)\n\u001b[1;32m      7\u001b[0m emulator \u001b[38;5;241m=\u001b[39m HybridEmulator(deep_ensemble\u001b[38;5;241m=\u001b[39mpredictor, normalizing_flow\u001b[38;5;241m=\u001b[39muncertainty_quantifier)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ise/models/hybrid.py:606\u001b[0m, in \u001b[0;36mDeepEnsemble.__init__\u001b[0;34m(self, weak_predictors, forcing_size, sle_size, num_predictors)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_choices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    600\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(),\n\u001b[1;32m    601\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(),\n\u001b[1;32m    602\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mL1Loss(),\n\u001b[1;32m    603\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mHuberLoss(),\n\u001b[1;32m    604\u001b[0m     ]\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# loss_probabilities = [.45, .05, .3, .2]\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweak_predictors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    607\u001b[0m         WeakPredictor(\n\u001b[1;32m    608\u001b[0m             lstm_num_layers\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, high\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    609\u001b[0m             lstm_hidden_size\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m], \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    610\u001b[0m             criterion\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\n\u001b[1;32m    611\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_choices,\n\u001b[1;32m    612\u001b[0m                 \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    613\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    614\u001b[0m             input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforcing_size,\n\u001b[1;32m    615\u001b[0m             output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msle_size,\n\u001b[1;32m    616\u001b[0m         )\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_predictors)\n\u001b[1;32m    618\u001b[0m     ]\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weak_predictors, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ise/models/hybrid.py:607\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_choices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    600\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(),\n\u001b[1;32m    601\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(),\n\u001b[1;32m    602\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mL1Loss(),\n\u001b[1;32m    603\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mHuberLoss(),\n\u001b[1;32m    604\u001b[0m     ]\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# loss_probabilities = [.45, .05, .3, .2]\u001b[39;00m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweak_predictors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 607\u001b[0m         WeakPredictor(\n\u001b[1;32m    608\u001b[0m             lstm_num_layers\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, high\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    609\u001b[0m             lstm_hidden_size\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m], \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    610\u001b[0m             criterion\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\n\u001b[1;32m    611\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_choices,\n\u001b[1;32m    612\u001b[0m                 \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    613\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    614\u001b[0m             input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforcing_size,\n\u001b[1;32m    615\u001b[0m             output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msle_size,\n\u001b[1;32m    616\u001b[0m         )\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_predictors)\n\u001b[1;32m    618\u001b[0m     ]\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weak_predictors, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/ise/models/hybrid.py:388\u001b[0m, in \u001b[0;36mWeakPredictor.__init__\u001b[0;34m(self, lstm_num_layers, lstm_hidden_size, input_size, output_size, dim_processor, scaler_path, ice_sheet, criterion)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# Initialize model layers\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLSTM(\n\u001b[1;32m    389\u001b[0m     input_size\u001b[38;5;241m=\u001b[39minput_size,\n\u001b[1;32m    390\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39mlstm_hidden_size,\n\u001b[1;32m    391\u001b[0m     batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    392\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39mlstm_num_layers,\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39mlstm_hidden_size, out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:770\u001b[0m, in \u001b[0;36mLSTM.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:89\u001b[0m, in \u001b[0;36mRNNBase.__init__\u001b[0;34m(self, mode, input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional, proj_size, device, dtype)\u001b[0m\n\u001b[1;32m     83\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout option adds dropout after all but last \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecurrent layer, so non-zero dropout expects \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers greater than 1, but got dropout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hidden_size, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size should be of type int, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(hidden_size)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size must be greater than zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: hidden_size should be of type int, got: int64"
     ]
    }
   ],
   "source": [
    "input_shape = X.shape[1]\n",
    "output_shape = y.shape[1]\n",
    "num_ensemble_members = 2\n",
    "\n",
    "predictor = DeepEnsemble(num_predictors=num_ensemble_members, forcing_size=input_shape, sle_size=output_shape)\n",
    "uncertainty_quantifier = NormalizingFlow(forcing_size=input_shape, sle_size=output_shape)\n",
    "emulator = HybridEmulator(deep_ensemble=predictor, normalizing_flow=uncertainty_quantifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a5dc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "emulator.fit(X, y, nf_epochs=10, de_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b8513",
   "metadata": {},
   "source": [
    "### Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, uncertainties = emulator.predict(np.array([[10, 11, 12]]), output_scaler=scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d26fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b427f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
